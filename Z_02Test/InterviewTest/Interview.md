## [MySQL]MySQL主从同步是如何实现的

主从同步的实现：master节点将更改写入binlog文件，slave节点读取binlog，写入slave的relay log 中，mysql线程读取relay log中的对数据的插入、更新或删除操作，同步到slave节点上，这个同步是有延迟的，无法做到实时同步，个人见解，如有错误烦请指教

Binary log：主数据库的二进制日志。
Relay log：从服务器的中继日志。
第一步：master在每个事务更新数据完成之前，将该操作记录串行地写入到binlog文件中。
第二步：salve开启一个I/O Thread，该线程在master打开一个普通连接，主要工作是binlog dump process。如果读取的进度已经跟上了master，就进入睡眠状态并等待master产生新的事件。I/O线程最终的目的是将这些事件写入到中继日志中。
第三步：SQL Thread会读取中继日志，并顺序执行该日志中的SQL事件，从而与主数据库中的数据保持一致。

## [数据结构]说一说ArrayList的实现原理

==**数组实现、默认容量为10、每次扩容1.5倍**==



**ArrayList是基于数组实现的，它的内部封装了一个Object[]数组。**

通过默认构造器创建容器时，该数组先被初始化为空数组，之后在首次添加数据时再将其初始化成长度为10的数组。我们也可以使用有参构造器来创建容器，并通过参数来显式指定数组的容量，届时该数组被初始化为指定容量的数组。

如果向ArrayList中添加数据会造成超出数组长度限制，则会触发自动扩容，然后再添加数据。扩容就是数组拷贝，将旧数组中的数据拷贝到新数组里，而新数组的长度为原来长度的1.5倍。

ArrayList支持缩容，但不会自动缩容，即便是ArrayList中只剩下少量数据时也不会主动缩容。如果我们希望缩减ArrayList的容量，则需要自己调用它的trimToSize()方法，届时数组将按照元素的实际个数进行缩减。

**加分回答**

**Set、List、Queue都是Collection的子接口**，它们都继承了父接口的iterator()方法，从而具备了迭代的能力。但是，相比于另外两个接口，List还单独提供了listIterator()方法，增强了迭代能力。iterator()方法返回Iterator迭代器，listIterator()方法返回ListIterator迭代器，并且ListIterator是Iterator的子接口。ListIterator在Iterator的基础上，增加了向前遍历的支持，增加了在迭代过程中修改数据的支持。

**延伸阅读**

```java
//ArrayList的关键代码如下：
// 默认容量
private static final int DEFAULT_CAPACITY = 10;

// 空数组（指定容量）
private static final Object[] EMPTY_ELEMENTDATA = {};

// 空数组（默认容量）
private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};
```
## [系统]如何打开一个大文件

 打开大文件的关键在于，不能直接将文件中的数据全部读取到内存中，以免引发OOM。

重点要考虑内存的利用问题，就是如何使用较小的内存空间来解决问题。

可以考虑的方式是，**==每次读取文件中的一部分内容，分多次处理这个文件==**，具体还要看打开文件的目的。



1. 如果我们打开的是**文本文件**，期望读取甚至分析该文件中的内容，则可以采用java.util.Scanner来逐行读取文件的内容。在Scanner遍历文件的过程中，每处理一行之后，我们都要丢弃对该行的引用，以节约内存。

2. 如果我们打开的是**字节文件**，期望拷贝或者搬运该文件中的内容，则可以采用缓冲流或NIO。每次利用缓冲区处理文件中的一小段数据，这样在处理过程中使用的内存空间便是很有限的，不会造成内存溢出的问题。

加分回答

  如果访问的是文本文件，我们还可以使用第三方类库来处理问题，例如Apache Commones IO库就提供了遍历文件的工具：**LineIterator**。它在迭代的过程中不会读取完整的文件，只会消耗较小的内存空间。



## [Redis]Redis有哪些数据类型

标准回答

  它主要提供了5种数据类型：

**字符串(string)、哈希(hash)、列表(list)、集合(set)、有序集合(zset)。**

Redis还提供了**Bitmap**、HyperLogLog、Geo类型，但这些类型都是基于上述核心数据类型实现的。

5.0版本中，**Redis新增加了Streams数据类型，它是一个功能强大的、支持多播的、可持久化的消息队列**。

1. string可以存储字符串、数字和二进制数据，除了值可以是String以外，所有的键也可以是string，string最大可以存储大小为512M的数据。

2. list保证数据线性有序且元素可重复，它支持lpush、blpush、rpop、brpop等操作，可以当作简单的消息队列使用，一个list最多可以存储2^32-1个元素。

3. hash的值本身也是一个键值对结构，最多能存储2^32-1个元素。

4. set是无序不可重复的，它支持多个set求交集、并集、差集，适合实现共同关注之类的需求，一个set最多可以存储2^32-1个元素。

5. zset是有序不可重复的，它通过给每个元素设置一个分数来作为排序的依据，一个zset最多可以存储2^32-1个元素。

加分回答

  每种类型支持多个编码，每一种编码采取一个特殊的结构来实现，各类数据结构内部的编码及结构：

1. string：编码分为int、raw、embstr。int底层实现为long，当数据为整数型并且可以用long类型表示时可以用long存储。embstr底层实现为占一块内存的SDS结构，当数据为长度不超过32字节的字符串时，选择以此结构连续存储元数据和值。raw底层实现为占两块内存的SDS，用于存储长度超过32字节的字符串数据，此时会在两块内存中分别存储元数据和值。

2. list：编码分为ziplist、linkedlist、quicklist（3.2以前版本没有quicklist）。ziplist底层实现为压缩列表，当元素数量小于512且所有元素长度都小于64字节时，使用这种结构来存储。linkedlist底层实现为双端链表，当数据不符合ziplist条件时，使用这种结构存储。3.2版本之后list采用quicklist的快速列表结构来代替前两种。

3. hash：编码分为ziplist、hashtable两种。其中ziplist底层实现为压缩列表，当键值对数量小于512，并且所有的键值长度都小于64字节时使用这种结构进行存储。hashtable底层实现为字典，当不符合压缩列表存储条件时，使用字典进行存储。

4. set：编码分为inset、hashtable。intset底层实现为整数集合，当所有元素都是整数值且数量不超过512个时使用该结构存储，否则使用字典结构存储。

5. zset：编码分为ziplist、skiplist。当元素数量小于128，并且每个元素长度都小于64字节时，使用ziplist压缩列表结构存储，否则使用skiplist的字典+跳表的结构存储。



## [Redis]缓存穿透、缓存击穿、缓存雪崩有什么区别，该如何解决？

标准回答

缓存穿透：

· 问题描述：

客户端查询根本不存在的数据，使得请求直达存储层，导致其负载过大，甚至宕机。出现这种情况的原因，可能是业务层误将缓存和库中的数据删除了，也可能是有人恶意攻击，专门访问库中不存在的数据。

· 解决方案：

1. 缓存空对象：存储层未命中后，仍将空值存入缓存层，客户端再次访问数据时，缓存层直接返回空值。

2. 布隆过滤器：将数据存入布隆过滤器，访问缓存之前以过滤器拦截，如果数据不存在则直接返回空值。

缓存击穿：

· 问题描述：

一份热点数据，它的访问量非常大。在其缓存失效的瞬间，大量请求直达存储层，导致服务崩溃。

· 解决方案：

1. 永不过期：热点数据不设置过期时间，所以不会出现上述问题，这是“物理”上的永不过期。或者为每个数据设置逻辑过期时间，当发现该数据逻辑过期时，使用单独的线程重建缓存。

2. 加互斥锁：对数据的访问加互斥锁，当一个线程访问该数据时，其他线程只能等待。这个线程访问过后，缓存中的数据将被重建，届时其他线程就可以直接从缓存中取值。

缓存雪崩：

· 问题描述：

在某一时刻，缓存层无法继续提供服务，导致所有的请求直达存储层，造成数据库宕机。

可能是缓存中有大量数据同时过期，

也可能是Redis节点发生故障，导致大量请求无法得到处理。

· 解决方案：

1. 避免数据同时过期：设置过期时间时，附加一个随机数，避免大量的key同时过期。

2. 启用降级和熔断措施：在发生雪崩时，若应用访问的不是核心数据，则直接返回预定义信息/空值/错误信息。或者在发生雪崩时，对于访问缓存接口的请求，客户端并不会把请求发给Redis，而是直接返回。

3. 构建高可用的Redis服务：采用哨兵或集群模式，部署多个Redis实例，个别节点宕机，依然可以保持服务的整体可用。

---

**缓存穿透**:   是指缓存和数据库中都没有的数据，而用户不断发起请求。

解决方案：接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；



**缓存击穿**：缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期）。这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。

解决方案：①设置热点数据永远不过期。②加互斥锁



**缓存雪崩**：缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。和缓存击穿不同的是， 缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。

解决方案：

①设置热点数据永远不过期。

②如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。

③缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。



## [JUC]说一说线程同步的方式

标准回答

  Java主要通过加锁的方式实现线程同步，而锁有两类，分别是synchronized和Lock。

  synchronized可以加在三个不同的位置，对应三种不同的使用方式，这三种方式的区别是锁对象不同：

1. 加在普通方法上，则锁是当前的实例（this）。

2. 加在静态方法上，则锁是当前类的Class对象。

3. 加在代码块上，则需要在关键字后面的小括号里，显式指定一个对象作为锁对象。

  不同的锁对象，意味着不同的锁粒度，所以我们不应该无脑地将它加在方法前了事，尽管通常这可以解决问题。而是应该根据要锁定的范围，准确的选择锁对象，从而准确地确定锁的粒度，降低锁带来的性能开销。

  synchronized是比较早期的API，在设计之初没有考虑到超时机制、非阻塞形式，以及多个条件变量。若想通过升级的方式让synchronized支持这些相对复杂的功能，则需要大改它的语法结构，不利于兼容旧代码。因此，JDK的开发团队在1.5引入了Lock，并通过Lock支持了上述的功能。Lock支持的功能包括：支持响应中断、支持超时机制、支持以非阻塞的方式获取锁、支持多个条件变量（阻塞队列）。

【加分回答】

  synchronized采用“CAS+Mark Word”实现，为了性能的考虑，并通过锁升级机制降低锁的开销。在并发环境中，synchronized会随着多线程竞争的加剧，按照如下步骤逐步升级：无锁、偏向锁、轻量级锁、重量级锁。

  Lock则采用“CAS+volatile”实现，其实现的核心是AQS。AQS是线程同步器，是一个线程同步的基础框架，它基于模板方法模式。在具体的Lock实例中，锁的实现是通过继承AQS来实现的，并且可以根据锁的使用场景，派生出公平锁、不公平锁、读锁、写锁等具体的实现。

【延伸阅读】

  想要保证线程安全，不止线程同步一种手段，还包含如下常见办法：

1. 原子类：可以用原子方式更新一个变量，即在变量未被其他线程修改时才出发更新，否则会引发失败。

2. volatile：volatile是一个轻量级的锁，它通过保证内存可见性的办法来实现线程安全。

3. 并发工具：还有很多并发工具类，一样可以保证线程安全，如Semaphore、CountDownLatch、CyclicBarrier。







对象关系模型 分析
