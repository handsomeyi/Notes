# ==MQTest==

什么是mq? 

你为什么用mq? 

为什么用mq? 

为什么不用ooxx? 

可靠性怎么保证? 

重复消息? 

丢失消息? 

---

## 目标: 架构能力

### MQ: 边界(queue)

【解耦. 异步. 消峰】: 发送文件(很大的东西)

message=size: kafka: 1M, rocketmq: 4M, rabbitmq: 2G, 512M

queue: FIFO, del, offset



producer: 投递可靠性

consumer: 消费可靠性

broker: 

Partition: 

topic: 



amqp

exchange:direct,fanout,topic,headrs

queue:

binding:ex+queue

routingkey:ex+(routingkey)+queue

问题: dirct可不可以一个routingkey通过dirctEX发送给多个queue



延迟

过期

重试

死信

幂等

重复

可靠

有序

消息大小

发送机制



# ==MQ基础==

## 为什么使用MQ? MQ的优点

1. 主要是为了: **解耦, 异步, 削峰**. 

   - 异步处理 = 相比于传统的串行, 并行方式, 提高了系统吞吐量. 
   - 应用解耦 = 系统间通过消息通信, 不用关心其他系统的处理. 
   - 流量削锋 = 可以通过消息队列长度控制请求量；可以缓解短时间内的高并发请求. 
   - 日志处理 = 解决大量日志传输. 
   - 消息通讯 = 消息队列一般都内置了高效的通信机制, 因此也可以用在纯的消息通讯. 比如实现点对点消息队列, 或者聊天室等. 

2. **解耦**: A 系统发送数据到 BCD 三个系统, 通过接口调用发送. 这种情况下A只需要维护对消息队列的提供功能, 不需要考虑人家怎么消费, 是否成功, 谁要消费, 与我无瓜. => 异步解耦化.

   **异步**: 就是说写入MQ成功就直接返回, 后续BCD的写库只要MQ消费完就OK.

   A 系统接收一个请求, 需要在自己本地写库, 还需要在 BCD 三个系统写库, 自己本地写库要 3ms, BCD 三个系统分别写库要 300ms, 450ms, 200ms. 最终请求总延时是 3 + 300 + 450 + 200 = 953ms, 接近 1s, 用户感觉搞个什么东西, 慢死了慢死了. 用户通过浏览器发起请求. 如果使用 MQ, 那么 A 系统连续发送 3 条消息到 MQ 队列中, 假如耗时 5ms, A 系统从接受一个请求到返回响应给用户, 总时长是 3 + 5 = 8ms. 

   **削峰**: 通过队列长度限制, 减少高峰时期对服务器压力. 

## 消息队列有什么优缺点? RabbitMQ有什么优缺点? 

**优点**: 异步, 解耦, 削峰.

**缺点**: 

- 系统可用性降低
- 系统复杂度提高: 重复消费, 可靠性传输
- 一致性问题

实际上消息队列是一个非常复杂的架构, 有利有弊, 但是改用还是得用, 也得对其缺点进行另外的处理.

## 你们公司生产环境用的是什么消息中间件? **综合对比如下**

- ActiveMQ => 老牌MQ, 过去用的多, 但现在对高并发不是特别支持, 对简单的异步, 解耦可用.
- RabbitMQ => erlang原生RabbitMQ, 高并发, 高吞吐, 性能很高, 可视化, 社区活跃.
- RocketMQ => 姓马云的马, 基于Java,  超高并发, 高吞吐, 性能卓越, 分布式事务.
- Kafka => 小于RocketMQ, 超高吞吐量的实时日志采集, 实时数据同步, 实时数据计算. (大数据体系)

## ==Kafka. ActiveMQ. RabbitMQ. RocketMQ== 有什么优缺点? 

|            | ActiveMQ                                               | RabbitMQ                                                     | RocketMQ                                                     | Kafka                                                        | ZeroMQ               |
| :--------- | :----------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- | -------------------- |
| 单机吞吐量 | 比RabbitMQ低                                           | 2.6w/s(消息做持久化)                                         | 11.6w/s                                                      | 17.3w/s                                                      | 29w/s                |
| 开发语言   | Java                                                   | Erlang                                                       | Java                                                         | Scala/Java                                                   | C                    |
| 主要维护者 | Apache                                                 | Mozilla/Spring                                               | Alibaba                                                      | Apache                                                       | iMatix, 创始人已去世 |
| 成熟度     | 成熟                                                   | 成熟                                                         | 开源版本不够成熟                                             | 比较成熟                                                     | 只有C, PHP等版本成熟 |
| 订阅形式   | 点对点(p2p), 广播(发布=订阅)                           | 提供了4种: direct, topic ,Headers和fanout. fanout就是广播模式 | 基于topic/messageTag以及按照消息类型, 属性进行正则匹配的发布订阅模式 | 基于topic以及按照topic进行正则匹配的发布订阅模式             | 点对点(p2p)          |
| 持久化     | 支持少量堆积                                           | 支持少量堆积                                                 | 支持大量堆积                                                 | 支持大量堆积                                                 | 不支持               |
| 顺序消息   | 不支持                                                 | 不支持                                                       | 支持                                                         | 支持                                                         | 不支持               |
| 性能稳定性 | 好                                                     | 好                                                           | 一般                                                         | 较差                                                         | 很好                 |
| 集群方式   | 支持简单集群模式, 比如’主=备’, 对高级集群模式支持不好. | 支持简单集群, '复制’模式, 对高级集群模式支持不好.            | 常用 多对’Master=Slave’ 模式, 开源版本需手动切换Slave变成Master | 天然的‘Leader=Slave’无状态集群, 每台服务器既是Master也是Slave | 不支持               |
| 管理界面   | 一般                                                   | 较好                                                         | 一般                                                         | 无                                                           | 无                   |

- 一般的业务系统要引入 MQ, 最早大家都用 ActiveMQ, 但是现在确实大家用的不多了, 没经过大规模吞吐量场景的验证, 社区也不是很活跃, 所以大家还是算了吧, 我个人不推荐用这个了；
- 后来大家开始用 RabbitMQ, 但是确实 **erlang** 语言阻止了大量的 Java 工程师去深入研究和掌控它, 对公司而言, 几乎处于不可控的状态, 但是确实人家是**开源**的, 比较**稳定的支持**, **活跃度也高**；
- 不过现在确实越来越多的公司会去用 RocketMQ, 确实很不错, 毕竟是**阿里出品**, 但社区可能有突然黄掉的风险(目前 RocketMQ **已捐给 [Apache](https://github.com/apache/rocketmq)**, 但 GitHub 上的活跃度其实不算高)对自己公司技术实力有绝对自信的, 推荐用 RocketMQ, 否则回去老老实实用 RabbitMQ 吧, 人家有活跃的开源社区, 绝对不会黄. 
- 所以**中小型公司**, 技术实力较为一般, 技术挑战不是特别高, 用 RabbitMQ 是不错的选择；**大型公司**, 基础架构研发实力较强, 用 RocketMQ 是很好的选择. 
- 如果是**大数据领域**的实时计算, 日志采集等场景, **==用 Kafka 是业内标准的==**, 绝对没问题, 社区活跃度很高, 绝对不会黄, 何况几乎是全世界这个领域的事实性规范. 

## MQ 有哪些常见问题? 如何解决这些问题? 

**顺序问题**

- 保证生产者 = MQServer = 消费者是一对一对一的关系
- 缺陷:
  - 并行度就会成为消息系统的瓶颈(吞吐量不够)
  - 更多的异常处理, 比如: 只要消费端出现问题, 就会导致整个处理流程阻塞, 我们不得不花费更多的精力来解决阻塞的问题. 通过合理的设计或者将问题分解来规避. 
  - 不关注乱序的应用实际大量存在
  - 队列无序并不意味着消息无序 所以从业务层面来保证消息的顺序而不仅仅是依赖于消息系统, 是一种更合理的方式. 

**重复问题** => 根本原因: 网络不可达

- 使得消费者业务逻辑保持幂等性.
- 保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现. 

## 说说设计MQ思路? 

- 比如说这个消息队列系统, 我们从以下几个角度来考虑一下: 
- 首先这个 mq 得支持可伸缩性吧, 就是需要的时候快速扩容, 就可以增加吞吐量和容量, 那怎么搞? 设计个分布式的系统呗, 参照一下 kafka 的设计理念, broker => topic => Partition, 每个 Partition 放一个机器, 就存一部分数据. 如果现在资源不够了, 简单啊, 给 topic 增加 Partition, 然后做数据迁移, 增加机器, 不就可以存放更多数据, 提供更高的吞吐量了? 
- 其次你得考虑一下这个 mq 的数据要不要落地磁盘吧? 那肯定要了, 落磁盘才能保证别进程挂了数据就丢了. 那落磁盘的时候怎么落啊? 顺序写, 这样就没有磁盘随机读写的寻址开销, 磁盘顺序读写的性能是很高的, 这就是 kafka 的思路. 
- 其次你考虑一下你的 mq 的可用性啊? 这个事儿, 具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制. 多副本 => leader & follower => broker 挂了重新选举 leader 即可对外服务. 

能不能支持数据 0 丢失啊? 可以的, 参考我们之前说的那个 kafka 数据零丢失方案. 

# ==RabbitMQ==

## 什么是RabbitMQ? 

**RabbitMQ是一款开源的, Erlang编写的, 基于AMQP协议的消息中间件**

**基于AMQP**
在服务器中, 三个主要功能模块连接成一个处理链完成预期的功能: 
"exchange"接收发布应用程序发送的消息, 并根据一定的规则将这些消息路由到"消息队列". 
"message queue"存储消息, 直到这些消息被消费者安全处理完为止. 
"binding"定义了exchange和message queue之间的关联, 提供路由规则. 

## rabbitmq 的使用场景

- 服务间异步通信
- 顺序消费
- **定时任务**
- 请求削峰

## RabbitMQ基本概念

![image-20220416173245947](https://s2.loli.net/2022/04/16/uGXZqwaHVg8tk9U.png)

- **Broker**:  简单来说就是消息队列服务器实体
- **Exchange**:  消息交换机, 它指定消息按什么规则, 路由到哪个队列
- **Queue**:  消息队列载体, 每个消息都会被投入到一个或多个队列
- **Binding**:  绑定, 它的作用就是把**exchange和queue**按照路由规则绑定起来
- **Routing Key**:  路由关键字, exchange根据这个关键字进行消息投递
- **VHost**:  vhost 可以理解为虚拟 broker , 即 mini-RabbitMQ server. 其内部均含有独立的 queue, exchange 和 binding 等, 但最最重要的是, 其拥有独立的权限系统, 可以做到 vhost 范围的用户控制. 当然, 从 RabbitMQ 的全局角度, vhost 可以作为不同权限隔离的手段(一个典型的例子就是不同的应用可以跑在不同的 vhost 中). 
- **Producer**:  消息生产者, 就是投递消息的程序
- **Consumer**:  消息消费者, 就是接受消息的程序
- **Channel**:  消息通道, 在客户端的每个连接里, 可建立多个channel, 每个channel代表一个会话任务

由Exchange, Queue, RoutingKey三个才能决定一个从Exchange到Queue的唯一的线路. 

**RabbitMQ高可用集群**

![image-20220416173850260](https://s2.loli.net/2022/04/16/wCtkfTLWmyg2MXh.png)

## RabbitMQ的工作模式

- **simple模式(即最简单的收发模式)**

  ![img](https://s2.loli.net/2022/04/16/TefjsyzEotHxI4d.png)

  消费者拿走消息后, 队列自动删除消息, 为了保证正确消费, 可手动设置ack, 正确消费完及时返回ack, 否则会导致内存溢出.

- **work工作模式(资源的竞争)**

  ![img](https://s2.loli.net/2022/04/16/V13byd4lCDSrL2x.png)

  消费者可以有多个, 同时监听同一个队列, 防止重复消费**得加锁**(synchronized).

- **publish/subscribe发布订阅(共享资源)**

  ![img](https://s2.loli.net/2022/04/16/ZBucR3nIOt5h4XP.png)

  每个消费者监听自己的队列, 生产者发给broker, 通过exchange转发到此交换机的每个队列.

  ==避免了重复消费, 不用加锁==.

- **routing路由模式**

  ![img](https://s2.loli.net/2022/04/16/Foe4TYtsZKbwU6N.png)

  **交换机**根据消息的一个**info**字符串, 来决定**路由到哪个**消息队列.

  这个路由逻辑可自行实现.

  业务场景: error 通知, Exception, 错误通知, 客户通知等.

  自定义key路由, 吧错误封装成消息, 根据错误类型发送到不同queue, 定制不同处理器consumer解决错误.

- **topic 主题模式(增加了模糊匹配的路由模式)**

  ![img](https://s2.loli.net/2022/04/16/yRo64lAW1PqIjgB.png)

  星号井号代表通配符

  星号代表多个单词,井号代表一个单词

  路由功能添加模糊匹配

  消息产生者产生消息,把消息交给交换机

  交换机根据key的规则模糊匹配到对应的队列,由队列的监听消费者接收消息消费

  (在我的理解看来就是routing查询的一种模糊匹配, 就类似sql的模糊查询方式)

## 如何保证RabbitMQ消息的顺序性? 

- 拆分多个 queue, 每个 queue 一个 consumer, 就是多一些 queue 而已, 确实是麻烦点；
- 或者就一个 queue 但是对应一个 consumer, 然后这个 consumer 内部用内存队列做排队, 然后分发给底层不同的 worker 来处理. (? 感觉也不严谨, 如何保证底层worker顺序处理呢, 各个worker有相互通讯机制? )

## 消息如何分发? 

- 单个队列多个消费者: 循环(round-robin)分发,.
- 多个队列各自消费者: 通过 **路由模式交换机** + **info字符串** 实现业务相关的分发.

## 消息怎么路由? 

消息提供方->路由->一至多个队列消息发布到交换器时, 消息将拥有一个路由键(routing key), 在消息创建时设定. 通过队列路由键, 可以把队列绑定到交换器上. 消息到达交换器后, RabbitMQ 会将消息的路由键与队列的路由键进行匹配(针对不同的交换器有不同的路由规则)；

常用的交换器主要分为一下三种: 

fanout: 如果交换器收到消息, 将会广播到所有绑定的队列上

direct: 如果路由键完全匹配, 消息就被投递到相应的队列

topic: 可以使来自不同源头的消息能够到达同一个队列.  使用 topic 交换器时, 可以使用通配符

## 消息基于什么传输? 

- TCP连接创建与销毁开销大, 并发数受系统资源限制, 造成性能瓶颈.

- 信道的方式来传输数据

  信道是基于TCP连接的虚拟连接, 并且TCP链接上的信道数量没有限制.

  **信道之于TCP连接 => 协程之于线程**

## 如何保证消息不被重复消费? 或者说, 如何保证消息消费时的幂等性? 

- 为何会重复消费?

  因为网络传输不是完全可靠的, ack可能没有返回到队列, 队列不知道被消费过 => 重复消费.

- 解决方案 ==(**额外冗余处理**与**提前判断**的取舍 => 谁快用谁)==

  ​	**额外冗余处理:** 保持消息处理逻辑的幂等性

  ​	**提前判断**: 写入消息队列时做唯一标识, 消费时, 判断此标识是否被消费过
  

## 如何确保消息正确地发送至 RabbitMQ?  如何确保消息接收方消费了消息? 

- **发送方确认模式**

  将信道设置成 confirm 模式(发送方确认模式), 则所有在信道上发布的消息都会被指派一个唯一的 ID. 
  一旦消息被投递到目的队列后, 或者消息被写入磁盘后(可持久化的消息), 信道会发送一个确认ack给生产者(包含消息唯一 ID). 
  如果 RabbitMQ 发生内部错误从而导致消息丢失, 会发送一条 nack(notacknowledged, 未确认)消息. 
  发送方确认模式是异步的, 生产者应用程序在等待确认的同时, 可以继续发送消息. 当确认消息到达生产者应用程序, 生产者应用程序的回调方法就会被触发来处理确认消息. 

- **接收方确认机制**

  消费者接收每一条消息后都必须进行确认(消息接收和消息确认是两个不同操作). 只有消费者确认了消息, RabbitMQ 才能安全地把消息从队列中删除. 

  这里并没有用到超时机制, RabbitMQ 仅通过 Consumer 的连接中断来确认是否需要重新发送消息. 也就是说, 只要连接不中断, RabbitMQ 给了 Consumer 足够长的时间来处理消息. 保证数据的最终一致性；

  下面罗列几种特殊情况

  - 如果消费者接收到消息, 在确认之前断开了连接或取消订阅, RabbitMQ 会认为消息没有被分发, 然后重新分发给下一个订阅的消费者. (可能存在消息重复消费的隐患, 需要去重)
  - 如果消费者接收到消息却没有确认消息, 连接也未断开, 则 RabbitMQ 认为该消费者繁忙, 将不会给该消费者分发更多的消息. 

## 如何保证RabbitMQ消息的可靠传输? 

有可能产生消息丢失.

丢失分为如下三种

- **生产者丢失消息** => transaction和confirm模式

  从生产者弄丢数据这个角度来看, RabbitMQ提供transaction和confirm模式来确保生产者不丢消息；

  transaction机制就是说: 发送消息前, 开启事务(channel.txSelect()),然后发送消息, 如果发送过程中出现什么异常, 事务就会回滚(channel.txRollback()),如果发送成功则提交事务(channel.txCommit()). 然而, 这种方式有个缺点: 吞吐量下降；

  confirm模式用的居多: 一旦channel进入confirm模式, 所有在该信道上发布的消息都将会被指派一个唯一的ID(从1开始), 一旦消息被投递到所有匹配的队列之后；

  rabbitMQ就会发送一个ACK给生产者(包含消息的唯一ID), 这就使得生产者知道消息已经正确到达目的队列了；

  如果rabbitMQ没能处理该消息, 则会发送一个Nack消息给你, 你可以进行重试操作. 

- **消息队列丢数据** => 消息持久化

  处理消息队列丢数据的情况, 一般是开启持久化磁盘的配置. 

  这个持久化配置可以和confirm机制配合使用, 你可以在消息持久化磁盘后, 再给生产者发送一个Ack信号. 

  这样, 如果消息持久化磁盘之前, rabbitMQ阵亡了, 那么生产者收不到Ack信号, 生产者会自动重发. 

  那么如何持久化呢？

  这里顺便说一下吧, 其实也很容易, 就下面两步

  1. 将queue的持久化标识durable设置为true,则代表是一个持久的队列
  2. 发送消息的时候将deliveryMode=2

  这样设置以后, 即使rabbitMQ挂了, 重启后也能恢复数据

- **消费者丢失消息** => 自动确认消息模式, 手动返回ack即可

  消费者在收到消息之后, 处理消息之前, 会自动回复RabbitMQ已收到消息；

  如果这时处理消息失败, 就会丢失该消息；

  解决方案: 处理消息成功后, 手动回复确认消息. 

## 为什么不应该对所有的 message 都使用持久化机制? 

- 写磁盘必然导致效率低 => 可能有10倍的吞吐量差距.

- RabbitMQ内置cluster方案的坑

  **message => persistent, queue => no durable**

  那么当该 queue 的 owner node 出现异常后, 在未重建该 queue 前, 发往该 queue 的 message 将被 blackholed

  **message => persistent, queue => durable**

  那么当 queue 的 owner node 异常且无法重启的情况下, 则该 queue 无法在其他 node 上重建, 只能等待其 owner node 重启后, 才能恢复该 queue 的使用, 而在这段时间内发送给该 queue 的 message 将被 blackholed

- 是否持久化, 需要结合业务和性能要求设计, 若想达到单机10w吞吐量

  ​	1. 可用SSD快速持久化

  ​	2. 关键信息持久化.

## 如何保证高可用的? RabbitMQ 的集群

图见第一点

![image-20220416173850260](https://s2.loli.net/2022/04/16/XrKcngVuBpa6Iy3.png)

RabbitMQ基于主从实现高可用 => 两种, 普通集群模式, 镜像集群模式.

- **普通集群模式** => 虚假的高可用 => 提高吞吐量

  多个机器启动RabbitMQ实例, 生产者发过来的消息只会放在一个RabbitMQ实例, 其他实例同步的是queue的元数据(通过元数据找到实际queue), 然后拉取实际数据过来.
  实际上就是多个节点服务某个queue读写, 主要是提高吞吐量的.

- **镜像集群模式** => 真实的高可用 => 真·高可用

  多个机器启动RabblitMQ, 并且所有数据都和元数据都在每个queue上, 每次写消息伴随着大量同步.
  某个机器宕机了, 它的consumer也可以去其他节点上消费数据, 真·高可用.

  缺点在于: 如果消息多, 大量同步造成的网络带宽消耗问题.

## 如何解决消息队列的延时以及过期失效问题? 

- **MQ中消息失效** => 手动重新发到MQ

  如果用的RabbitMQ, 它是可以设置过期时间(TTL)的, 如果积压过久的消息会被清理掉.
  只能大家一起喝杯咖啡, 等高峰期过去后, 等用户睡觉了, 把丢失数据用临时程序查出来, 重新灌入MQ即可.
  也只能是这样了. 假设 1 万个订单积压在 mq 里面, 没有处理, 其中 1000 个订单都丢了, 你只能手动写程序把那 1000 个订单给查出来, 手动发到 mq 里去再补一次. 

## 消息队列满了以后该怎么处理? 有几百万消息持续积压几小时, 说说怎么解决? 

- **消息积压 => 临时紧急扩容**

  先修复consumer的问题, 确保其消费速度没问题, 然后停掉所有consumer.
  临时处理: 新建一个topic, Partition是原来的10倍, 建好原先十倍的queue数量.
  写一个临时分发数据的consumer程序, 把MQ中积压的数据轮询写入临时10倍queue.
  然后用10倍consumer的机器部署consumer, 对接好queue之后, 10倍速率消费消息.
  消费完积压数据后, 恢复原先架构.

- **MQ队列快满了** => 临时程序接入消息消费一个丢弃一个, 快速消费巨量数据.
  然后还要注意过期消息的补充, 晚上补数据吧.

# ==Kafka==

## 基础题

![image-20220417011116529](https://s2.loli.net/2022/04/17/Yk8ArtlCvSsO7c1.png)



![image-20220417011147668](https://s2.loli.net/2022/04/17/qMhfCrvQ31SBeuc.png)

### 基本概念

- **生产者(Producer)**和**消费者(Consumer)**

  

- **主题(Topic)与分区(Partition)**

  Topic就是某种消息, Partition就是实际的队列, topic中有多个Partition => 就像公路上多修了几条道.

- **Broker** 和**集群(Cluster)**

  一台机器就是一个Broker, 多个机器就是集群.

  目前的机器条件, 集群中一个Broker可以处理上万的分区和百万量级的消息.

  集群中某个Broker会成为Cluster Controller, 选举过程之前通过Zookeeper, 现在自研的Raft实现.

  Controller管理集群, 

- **多集群**

  数据隔离

  多数据中心, 异地容灾 => 有条件可以搭专线, 提速.

  可用**Kafka**提供的**MirrorMaker**实现, 它就是一个队列连接了两个集群.

- Kafka还有一个特点它是**基于offset**的, 数据消费后不会马上被删除, 删除策略是针对过期的 Segment 文件.

## 1. Apache Kafka 是什么?

Kafka 是一款**==分布式流处理框架==**, 用于**==实时构建流处理应用==**. 它有一个核心 的功能广为人知, 即作为**==企业级的消息引擎==**被广泛使用. 

### 讨论一：Kafka 存储在文件系统上

- **Kafka 的消息是存在于文件系统之上的**
- **如果是针对磁盘的顺序访问, 某些情况下它可能比随机的内存访问都要快, 甚至可以和网络的速度相差无几. **
- 任何发布到 Partition 的消息都会被追加到 Partition 数据文件的尾部, 这样的顺序写磁盘操作让 Kafka 的效率非常高(经验证, 顺序写磁盘效率比随机写内存还要高, 这是 Kafka 高吞吐率的一个很重要的保证)

### 讨论二：Kafka 中的底层存储设计

文件结构如下
一个Partition就是一个文件夹, topic不同只是前缀名.
每个Partition由Segment File组成, Segment File由index文件和log文件组成.

现在假设我们设置每个 Segment 大小为 500 MB, 并启动生产者向 topic1 中写入大量数据, topic1-0 文件夹中就会产生类似如下的一些文件：

```c++
    | --topic1-0
        | --00000000000000000000.index // 这里面有大概358768/2个二元组, 代表log内偏移量
        | --00000000000000000000.log // 这里面有368768个消息
        | --00000000000000368769.index
        | --00000000000000368769.log
        | --00000000000000737337.index // 文件名就是之前的消息总数
        | --00000000000000737337.log
        | --00000000000001105814.index
        | --00000000000001105814.log
    | --topic2-0
    | --topic2-1
```

**Segment 是 Kafka 文件存储的最小单位. **Segment 文件命名规则：Partition 全局的第一个 Segment 从 0 开始, 后续每个 Segment 文件名为上一个 Segment 文件最后一条消息的 offset 值. 数值最大为 64 位 long 大小, 19 位数字字符长度, 没有数字用0填充. 
如 00000000000000368769.index 和 00000000000000368769.log

![image-20220417113458321](https://s2.loli.net/2022/04/17/CdiqsuImKeDfWQ6.png)

- **.index**

  index中(3, 497) 3代表该消息为log文件中第三个message, 在Partition中为368771+3个message.

  497代表该消息在此分区的偏移地址为497.

  index采用了稀疏索引, 减少索引文件大小, index能通过内存查询, 减少磁盘IO.

- **.log**

  文件名就是之前的消息总数.

  由于消息在 Partition 的 Segment 数据文件中是顺序读写的, 且消息消费后不会删除(删除策略是针对过期的 Segment 文件), 这种顺序磁盘 IO 存储设计师 Kafka 高性能很重要的原因. 

- **查询指定offset的消息**

  通过segment文件名, 进行二分查找, 然后通过index得到偏移量, 就能拿出message.

### 讨论三：生产者设计概要

- 比如说大型交易系统, 消息不能丢失不能重复, 所以延迟稍微高一点.
- 比如说用户在网页上的点赞数量, 少量丢失是没问题的, 甚至不需要Broker返回消息. 甚至前端就可以直接出效果.
- 具体设计还要通过用户体验来设计取舍.

![image-20220417165732765](https://s2.loli.net/2022/04/17/1QkdXLKa7nvcCAP.png)

- **流程如下**

  流程如下：

  1. 首先, 我们需要创建一个ProducerRecord, 这个对象需要包含消息的主题(topic)和值(value), 可以选择性指定一个键值(key)或者分区(partition). 
  2. 发送消息时, 生产者会对键值和值序列化成字节数组, 然后发送到分配器(partitioner). 
  3. 如果我们指定了分区, 那么分配器返回该分区即可；否则, 分配器将会基于键值来选择一个分区并返回. 
  4. 选择完分区后, 生产者知道了消息所属的主题和分区, 它将这条记录添加到相同主题和分区的批量消息中, 另一个线程负责发送这些批量消息到对应的Kafka broker. 
  5. 当broker接收到消息后, 如果成功写入则返回一个包含消息的主题, 分区及位移的RecordMetadata对象, 否则返回异常. 
  6. 生产者接收到结果后, 对于异常可能会进行重试. 

### 讨论四：消费者设计概要

我们可以通过增加消费组的消费者来进行水平扩展提升消费能力. 
创建topic时**==尽量使用比较多的分区数==**, 这样可以在消费负载高的情况下增加消费者来提升性能. 
消费者的数量不应该比分区数多.(多了无效)

- **消费者与消费组**

  Kafka消费者是**消费组**的一部分, 当多个消费者形成一个消费组来消费主题时, 每个消费者会收到不同分区的消息. 

  分区对应消费者: N == 1, N == 2, ..., N == N

- **消费组与分区重平衡**

  消费者宕机时, 其负责的分区会被分配给其他分区雨露均沾.

  **不过也需要注意到, 在重平衡期间, 所有消费者都不能消费消息, 因此会造成整个消费组短暂的不可用. **

- **心跳机制**

  消费者通过定期发送心跳(hearbeat)到一个作为组协调者(group coordinator)的 broker 来保持在消费组内存活. 

- **Partition 与消费模型**

  Kafka 只会保证在 Partition 内消息是有序的, 而不管全局的情况. 

  Partition 中的消息可以被(不同的 Consumer Group)多次消费, 所以Partition 会为每个 Consumer Group 保存一个偏移量, 记录 Group 整体消费到的位置.

- **Kafka为什么是pull模型?**

  消息队列有两种形式, 消费者向MQ拉(pull)数据, MQ向消费者推(push)数据.
  Kafka是前者, MQ被动提供数据, 消费者有空就来拉数据消费.
  pull拉数据可以根据消费者的消耗速率来消费消息, 更符合MQ的逻辑.
  而push推数据不易适应不同速率的消费者, 对于consumer宕机也不好处理, 缺点挺多.

  pull 模式可简化 broker 的设计, Consumer 可自主控制消费消息的速率, 同时 Consumer 可以自己控制消费方式——即可批量消费也可逐条消费, 同时还能选择不同的提交方式从而实现不同的传输语义. 

### 讨论五：Kafka 如何保证可靠性

- 对于一个分区来说, 它的消息是有序的. 如果一个生产者向一个分区先写入消息A, 然后写入消息B, 那么消费者会先读取消息A再读取消息B. 
- 当消息写入所有in-sync状态的副本后, 消息才会认为**已提交（committed）**. 这里的写入有可能只是写入到文件系统的缓存, 不一定刷新到磁盘. 生产者可以等待不同时机的确认, 比如等待分区主副本写入即返回, 后者等待所有in-sync状态副本写入才返回. 
- 一旦消息已提交, 那么只要有一个副本存活, 数据不会丢失. 
- 消费者只能读取到已提交的消息. 





## 2. 什么是消费者组?(Kafka独有)

- **定义**: 

  即消费者组是 Kafka 提供的**==可扩展==**且具**==有容错性==**的消费者机制. 

- **原理**:

  在 Kafka 中, 消费者组是一个由**多个消费者实例构成**的组. 多个实例共同订阅若干个主题, 实现**共同消费**. 同一个组下的每个实例都配置有 **相同的组 ID**, 被分配不同的订阅分区. 当某个实例挂掉的时候, 其他实例会自动地承担起 它负责消费的分区. 

- **消费者组的题目方向(引导面试方向)**

  移值原理 => **消费者组的位移提交机制**
  Kafka Broker => **消费者组与 Broker 之间的交互**
  Producer => yid: "**消费者组要消费的数据完全来自于 Producer 端生产的消息, 我对 Producer 还是比较熟悉的**"

## 3. 在 Kafka 中, ZooKeeper 的作用是什么?

- **存放元数据**
  是指**主题分区**的所有数据都保存在 ZooKeeper 中, 且以它保存的数据为权威, 其他 "人" 都要与它保持对齐. 

- **成员管理**

  是指 Broker 节点的注册, 注销以及属性变更, 等等. 

- **Controller 选举**

  是指选举集群 Controller, 而其他管理类任务包括但不限于主题删除, 参数配置等. 

  

- **以前**

  Kafka 使用 ZooKeeper 存放集群元数据, 成员管理, Controller 选举, 以及其他一些管理类任务. 

- **现在**

  Kafka早在2.8已经实现Controller自选举了, KIP-500大多都实现了, 自研的基于Raft的共识算法.

## 4. 解释下 Kafka 中位移(offset)的作用

- 在 Kafka 中, 每个 主题分区下的每条消息都被赋予了一个唯一的 ID 数值, 用于标识它在分区中的位置. 这个 ID 数值, 就被称为位移, 或者叫偏移量. 一旦消息被写入到分区日志, 它的位移值将不能 被修改. 
- **引导面试方向**
  1. 如果你深谙 ==Broker 底层日志写入的逻辑==, 可以强调下**消息在日志中的存放格式**;
  2. 如果你明白位移值一旦被确定不能修改, 可以强调下"**Log Cleaner 组件都不能影响位移值**"这件事情;
  3. 如果你对消费者的概念还算熟悉, 可以再详细说说**位移值**和**消费者位移值**之间的区别. 

## 5. 阐述下 Kafka 中的领导者副本(Leader Replica)和追随者副本 (Follower Replica)的区别

- 这道题表面上是考核你对 Leader 和 Follower 区别的理解, 但很容易引申到 Kafka 的同步 机制上. 因此, 我建议你主动出击, 一次性地把隐含的考点也答出来, 也许能够暂时把面试 官"唬住", 并体现你的专业性. 

- **标准答案**

  **Kafka 副本当前分为领导者副本和追随者副本. 只有 Leader 副本才能 对外提供读写服务, 响应 Clients 端的请求. Follower 副本只是采用拉(PULL)的方 式, 被动地同步 Leader 副本中的数据, 并且在 Leader 副本所在的 Broker 宕机后, 随时 准备应聘 Leader 副本. **

- **附加项**

  **强调 Follower 副本也能对外提供读服务**. 自 Kafka 2.4 版本开始, 社区通过引入新的 Broker 端参数, 允许 Follower 副本有限度地提供读服务. 

  **强调 Leader 和 Follower 的消息序列在实际场景中不一致**. 很多原因都可能造成 Leader 和 Follower 保存的消息序列不一致, 比如程序 Bug, 网络问题等. 这是很严重 的错误, 必须要完全规避. 你可以补充下, 之前确保一致性的主要手段是高水位机制,  但高水位值无法保证 Leader 连续变更场景下的数据一致性, 因此, 社区引入了 Leader Epoch 机制, 来修复高水位值的弊端. 关于"Leader Epoch 机制", 国内的资料不是 很多, 它的普及度远不如高水位, 不妨大胆地把这个概念秀出来, 力求惊艳一把. 

## 6. 如何设置 Kafka 能接收的最大消息的大小?

**这道题除了要回答消费者端的参数设置之外, 一定要加上 Broker 端的设置, 这样才算完整**. 毕竟, 如果 Producer 都不能向 Broker 端发送数据很大的消息, 又何来消费一说呢? 因此, 你需要同时设置 Broker 端参数和 Consumer 端参数. 

- Broker 端参数: **message.max.bytes**, **max.message.bytes**(主题级别)和**replica.fetch.max.bytes**
- Consumer 端参数: **fetch.message.max.bytes**.

Broker 端的最后一个参数比较容易遗漏. 我们必须调整 Follower 副本能够接收的最大消 息的大小, 否则, 副本同步就会失败. 因此, 把这个答出来的话, 就是一个加分项. 

## 7. 监控 Kafka 的框架都有哪些?

- **Kafka Manager**:应该算是最有名的专属 Kafka 监控框架了, 是独立的监控系统. 
- **Kafka Monitor**:LinkedIn 开源的免费框架, 支持对集群进行系统测试, 并实时监控测
  试结果. 
- **CruiseControl**:也是 LinkedIn 公司开源的监控框架, 用于实时监测资源使用率, 以及 提供常用运维操作等. 无 UI 界面, 只提供 REST API. 
- **JMX 监控**:由于 Kafka 提供的监控指标都是基于 JMX 的, 因此, 市面上任何能够集成 JMX 的框架都可以使用, 比如 Zabbix 和 Prometheus. 
- **已有大数据平台自己的监控体系**:像 Cloudera 提供的 CDH 这类大数据平台, 天然就提 供 Kafka 监控方案. 
- **JMXTool**:社区提供的命令行工具, 能够实时监控 JMX 指标. 答上这一条, 属于绝对 的加分项, 因为知道的人很少, 而且会给人一种你对 Kafka 工具非常熟悉的感觉. 如果 你暂时不了解它的用法, 可以在命令行以无参数方式执行一下kafka-run-class.sh kafka.tools.JmxTool, 学习下它的用法. 

## 8. Broker 的 Heap Size 如何设置?

业界常用6GB, 不过你也可以通过默认JVM堆运行, 手动Full GC一次, 查看存活对象大小, 堆设为存活大小的1.5~2倍.

如何设置 Heap Size 的问题, 其实和 Kafka 关系不大, 它是一类非常通用的面试题目. 一旦你应对不当, 面试方向很有可能被引到 **JVM 和 GC** 上去, 那样的话, 你被问住的几率就 会增大. 因此, 我建议你简单地介绍一下 Heap Size 的设置方法, 并把重点放在 **Kafka Broker 堆大小设置的最佳实践**上. 

- **你可以这样回复**

  **任何 Java 进程 JVM 堆大小的设置都需要仔细地进行考量和测试. 一个常见的做法是, 以默认的初始 JVM 堆大小运行程序, 当系统达到稳定状态后, 手动触发一次 Full GC, 然后通过 JVM 工具查看 GC 后的存活对象大小. 之后, 将堆大小设 置成存活对象总大小的 1.5~2 倍. 对于 Kafka 而言, 这个方法也是适用的. 不过, 业界有个最佳实践, 那就是将 Broker 的 Heap Size 固定为 6GB. 经过很多公司的验证, 这个大小是足够且良好的. **

## 9. 如何估算 Kafka 集群的机器数量?

这道题目考查的是**机器数量和所用资源之间的关联关系**. 所谓资源, 也就是 **CPU, 内存, 磁盘和带宽**. 

- 通常来说, CPU 和内存资源的充足是比较容易保证的, 因此, 你需要从磁盘空间和带宽占用两个维度去评估机器数量. 
- 在预估磁盘的占用时, 你一定不要忘记计算**副本同步的开销**. 如果一条消息占用 1KB 的磁 盘空间, 那么, 在有 3 个副本的主题中, 你就需要 3KB 的总空间来保存这条消息. 显式地 将这些考虑因素答出来, 能够彰显你考虑问题的全面性, 是一个难得的加分项. 
- 对于评估带宽来说, 常见的带宽有 1Gbps 和 10Gbps, 但你要切记, **这两个数字仅仅是最大值**. 因此, 你最好和面试官确认一下给定的带宽是多少. 然后, 明确阐述出当带宽占用接 近总带宽的 90% 时, 丢包情形就会发生. 这样能显示出你的网络基本功. 

## 10. Leader 总是 =1, 怎么破?

在生产环境中, 你一定碰到过"某个主题分区不能工作了"的情形. 使用命令行查看状态的 话, 会发现 Leader 是 -1, 于是, 你使用各种命令都无济于事, 最后只能用"重启大 法". 

但是, 有没有什么办法, 可以不重启集群, 就能解决此事呢?这就是此题的由来. 

参考答案:**删除 ZooKeeper 节点 /controller, 触发 Controller 重选举.  Controller 重选举能够为所有主题分区重刷分区状态, 可以有效解决因不一致导致的 Leader 不可用问题**. 我几乎可以断定, 当面试官问出此题时, 要么就是他真的不知道怎么 解决在向你寻求答案, 要么他就是在等你说出这个答案. 所以, 千万别一上来就说"来个重 启"之类的话. 

## 提高题

## 1.Kafka 的设计时什么样的呢? 

![image-20220417011147668](https://s2.loli.net/2022/04/17/qMhfCrvQ31SBeuc.png)

## 2.数据传输的事务定义有哪三种? kafka事务?

数据传输的事务定义通常有以下三种级别：

- 最多一次: 消息不会被重复发送, 最多被传输一次, 但也有可能一次不传输
- 最少一次: 消息不会被漏发送, 最少被传输一次, 但也有可能被重复传输.
- 精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被一次而

且仅仅被传输一次, 这是大家所期望的

**Kafka事务**
http://matt33.com/2018/11/04/kafka-transaction/
理解版
https://www.jianshu.com/p/64c93065473e
https://www.cnblogs.com/middleware/p/9477133.html

## 3.Kafka 判断一个节点是否还活着有那两个条件? 

- 维护与Zookeeper或Kraft的连接
- 如果节点是follower, 必须及时同步leader的写, 延时不能太久.

## 4.producer 是否直接将数据发送到 broker 的 leader(主节点)? 

是的, 而其他的分发同步是其他节点自动拉取的.

所有Kafka节点会告知Producer, topic目标分区的leader是谁, 以及活跃的节点.

## 5. Kafa consumer 是否可以消费指定分区消息? 

Kafa consumer 消费消息时, 向 broker 发出"fetch"请求去消费特定分区的消息, consumer 指定消息在日志中的偏移量（offset）, 就可以消费从这个位置开始的消息, customer 拥有了 offset 的控制权, 可以向后回滚去重新消费之前的消息, 这是很有意义的

## 6. Kafka 消息是采用 Pull 模式, 还是 Push 模式? 

- Producer**推(Push)**消息到Broker.
- 各个Broker中冗余的Partition之间通过**拉(Pull)同步**.
- Consumer向Broker**拉(Pull)**消息. => **==肯定是拉嘛,因为基于消费者消费速度来消费消息, 扩消费者时方便.==**
  思路就是能消费就来消, 最大可利用消费者的性能.

Consumer的Pull有个问题, 当Broker没有可供消费的消息时, Consumer将不断轮询.
有个参数可以调整参数让Consumer阻塞直到 (**到达可pull的消息量阈值**) .

## 7.Kafka 存储在硬盘上的消息格式是什么? 

![image-20220417113458321](https://s2.loli.net/2022/04/17/CdiqsuImKeDfWQ6.png)

```bash
topic1-0
    00000000000000000000.index
    00000000000000000000.log
    00000000000000041342.index
    00000000000000041342.log
...
```

消息由一个固定长度的头部和可变长度的字节数组组成.
头部包含了 版本号, CRC32校验码.

- 消息长度: **4 bytes** (value: 1+4+n)
- 版本号: **1 byte**
- CRC 校验码: **4 bytes**
- 具体的消息: **n bytes**

## 8.Kafka 高效文件存储设计特点: 

- Kafka 把 topic 中一个 parition 大文件分成多个小文件段, 通过多个Segment File, 就容易定期清除或删除已经消费完文件, 减少磁盘占用. 
- 通过索引信息可以快速定位 message 和确定 response 的最大大小. 
- 某些数据可通过index文件**直接从memory读数据**, 而不是磁盘IO, 可减少磁盘IO.
- .index采用了稀疏索引, 可以大幅降低 index 文件元数据占用空间大小. 

## 9.Kafka 与传统消息系统之间有三个关键区别

- Kafka 持久化日志, 这些日志可以被重复读取和无限期保留
- Kafka 是一个分布式系统：它以集群的方式运行, 可以灵活伸缩, 在内部通过复制数据提升容错能力和高可用性
- Kafka 支持实时的流式处理

## 10.Kafka 创建 Topic 时如何将分区放置到不同的 Broker 中

- 副本因子不能大于 Broker 的个数；
- 第一个分区（编号为 0）的第一个副本放置位置是随机从 brokerList 选择的；
- 其他分区的第一个副本放置位置相对于第 0 个分区依次往后移. 也就是如果我们有 5 个Broker, 5 个分区, 假设第一个分区放在第四个 Broker 上, 那么第二个分区将会放在第五个 Broker 上；第三个分区将会放在第一个 Broker 上；第四个分区将会放在第二个Broker 上, 依次类推；
- 剩余的副本相对于第一个副本放置位置其实是由 nextReplicaShift 决定的, 而这个数也是随机产生的

## 11.Kafka 新建的分区会在哪个目录下创建

- 在启动 Kafka 集群之前, 我们需要配置好 log.dirs 参数, 其值是 Kafka 数据的存放目录, 这个参数可以配置多个目录, 目录之间使用逗号分隔, 通常这些目录是分布在不同的磁盘上用于提高读写性能. 

- 当然我们也可以配置 log.dir 参数, 含义一样. 只需要设置其中一个即可. 如果 log.dirs 参数只配置了一个目录, 那么分配到各个 Broker 上的分区肯定只能在这个目录下创建文件夹用于存放数据. 

- 但是如果 log.dirs 参数配置了多个目录, 那么 Kafka 会在哪个文件夹中创建分区目录呢？

- 答案是：Kafka 会在含有**==分区目录最少的文件夹==**中创建新的分区目录, 分区目录名为 Topic名+分区 ID. 注意, 是分区文件夹总数最少的目录, 而不是磁盘使用量最少的目录！也就是说, 如果你给 log.dirs 参数新增了一个新的磁盘, 新的分区目录肯定是先在这个新的磁盘上创建直到这个新的磁盘目录拥有的分区目录不是最少为止. 

## 12.Partition 的数据如何保存到硬盘

topic 中的多个 partition 以文件夹的形式保存到 broker, 每个分区序号从 0 递增, 且消息有序

Partition 文件下有多个 segment（xxx.index, xxx.log）

segment 文件里的 大小和配置文件大小一致可以根据要求修改 默认为 1g

如果大小大于 1g 时, 会滚动一个新的 segment 并且以上一个 segment 最后一条消息的偏移量命名
新segment名字就是此Partition前面的消息总数, 20位数, 不够的0填充.

每个partiton就是一个文件夹, partition里面分为segment file => 

偏移量.index => 稀疏索引, 指向的是实际log文件的行数, 

偏移量.log  => 消息 + 行数

## 13.kafka 的接收消息 ack 机制(参数设置3个值)

**request.required.acks 有三个值: 0, 1, -1**

- 0: 生产者不会等待 broker 的 ack, 这个延迟最低但是存储的保证最弱当 server 挂掉的时候就会丢数据
- 1: 服务端会等待 ack 值 leader 副本确认接收到消息后发送 ack 但是如果 leader 挂掉后他不确保是否复制完成新 leader 也会导致数据丢失
- -1: 同样在 1 的基础上 服务端会等所有的 follower 的副本受到数据后才会受到 leader 发出的 ack, 这样数据不会丢失



## 14.Kafka 的消费者如何消费数据

消费者每次消费数据的时候, 消费者都会记录消费的物理偏移量（offset）的位置等到下次消费时, 他会接着上次位置继续消费.

## 15.消费者负载均衡策略

一个消费者组中的一个Partition对应一个消费者成员, 他能保证每个消费者成员都能访问, 如果组中成员太多会有空闲的成员.

Partition N == Consumer 1
Partition N == Consumer (<=N)

## 16.数据有序(Kafka不能保证)

一个消费者组里它的内部是有序的
消费者组与消费者组之间是无序的

Kafka 只会保证在 Partition 内消息是有序的, 而不管全局的情况. 

## 17.kafaka 生产数据时数据的分组策略

生产者决定数据产生到集群的哪个 partition 中
每一条消息都是以（key, value）格式
Key 是由生产者发送数据传入
所以生产者（key）决定了数据产生到集群的哪个 partition

## 深度思考题

## 11. LEO. LSO. AR. ISR. HW 都表示什么含义?

- **LEO**:Log End Offset. 日志末端位移值或末端偏移量, 表示日志下一条待插入消息的 位移值. 举个例子, 如果日志有 10 条消息, 位移值从 0 开始, 那么, 第 10 条消息的位 移值就是 9. 此时, LEO = 10. 
- **LSO**:Log Stable Offset. 这是 Kafka 事务的概念. 如果你没有使用到事务, 那么这个 值不存在(其实也不是不存在, 只是设置成一个无意义的值). 该值控制了事务型消费 者能够看到的消息范围. 它经常与 Log Start Offset, 即日志起始位移值相混淆, 因为 有些人将后者缩写成 LSO, 这是不对的. 在 Kafka 中, LSO 就是指代 Log Stable Offset. 
- **AR**:Assigned Replicas. AR 是主题被创建后, 分区创建时被分配的副本集合, 副本个 数由副本因子决定. 
- **ISR**:In-Sync Replicas. Kafka 中特别重要的概念, 指代的是 AR 中那些与 Leader 保 持同步的副本集合. 在 AR 中的副本可能不在 ISR 中, 但 Leader 副本天然就包含在 ISR 中. 关于 ISR, **还有一个常见的面试题目是如何判断副本是否应该属于 ISR**. 目前的判断 依据是:**Follower 副本的 LEO 落后 Leader LEO 的时间, 是否超过了 Broker 端参数 replica.lag.time.max.ms 值**. 如果超过了, 副本就会被从 ISR 中移除. 
- **HW**:高水位值(High watermark). 这是控制消费者可读取消息范围的重要字段. 一 个普通消费者只能"看到"Leader 副本上介于 Log Start Offset 和 HW(不含)之间的 所有消息. 水位以上的消息是对消费者不可见的. 关于 HW, 问法有很多, 我能想到的 最高级的问法, 就是让你完整地梳理下 Follower 副本拉取 Leader 副本, 执行同步机制 的详细步骤. 这就是我们的第 20 道题的题目, 一会儿我会给出答案和解析. 

## 12. Kafka 能手动删除消息吗?

其实Kafka本身是不需要删除消息的, 本身提供了Segment过期时间策略, 当然也能手动删除.

- 对于设置了 Key 且参数 cleanup.policy=compact 的主题而言, 我们可以构造一条 <Key, null> 的消息发送给 Broker, 依靠 Log Cleaner 组件提供的功能删除掉该 Key 的消息. 
- 对于普通主题而言, 我们可以使用 kafka-delete-records 命令, 或编写程序调用 Admin.deleteRecords 方法来删除消息. 这两种方法殊途同归, 底层都是调用 Admin 的 deleteRecords 方法, 通过将分区 Log Start Offset 值抬高的方式间接删除消息. 

## 13. __consumer_offsets 是做什么用的?

这是一个内部主题, 公开的官网资料很少涉及到. 因此, 我认为, 此题属于面试官炫技一类 的题目. 你要小心这里的考点:该主题有 3 个重要的知识点, 你一定要全部答出来, 才会显得对这块知识非常熟悉. 

它是一个内部主题, 无需手动干预, 由 Kafka 自行管理. 当然, 我们可以创建该主题. 

它的主要作用是负责注册消费者以及保存位移值. 可能你对保存位移值的功能很熟悉,  但其实**该主题也是保存消费者元数据的地方. 千万记得把这一点也回答上**. 另外, 这里 的消费者泛指消费者组和独立消费者, 而不仅仅是消费者组. 

Kafka 的 GroupCoordinator 组件提供对该主题完整的管理功能, 包括该主题的创建,  写入, 读取和 Leader 维护等. 

## 14. 分区 Leader 选举策略有几种?

分区的 Leader 副本选举对用户是完全透明的, 它是由 Controller 独立完成的. 你需要回答的是, 在哪些场景下, 需要执行分区 Leader 选举. 每一种场景对应于一种选举策略. 当前, Kafka 有 4 种分区 Leader 选举策略. 

- **OfflinePartition Leader 选举**:每当有分区上线时, 就需要执行 Leader 选举. 所谓的分区上线, 可能是创建了新分区, 也可能是之前的下线分区重新上线. 这是最常见的分区 Leader 选举场景. 
- **ReassignPartition Leader 选举**:当你手动运行 kafka-reassign-partitions 命令, 或者是调用 Admin 的 alterPartitionReassignments 方法执行分区副本重分配时, 可能触发此类选举. 假设原来的 AR 是[1, 2, 3], Leader 是 1, 当执行副本重分配后, 副本集 合 AR 被设置成[4, 5, 6], 显然, Leader 必须要变更, 此时会发生 Reassign Partition Leader 选举. 
- **PreferredReplicaPartition Leader 选举**:当你手动运行 kafka-preferred-replica- election 命令, 或自动触发了 Preferred Leader 选举时, 该类策略被激活. 所谓的 Preferred Leader, 指的是 AR 中的第一个副本. 比如 AR 是[3, 2, 1], 那么,  Preferred Leader 就是 3. 
- **ControlledShutdownPartition Leader 选举**:当 Broker 正常关闭时, 该 Broker 上 的所有 Leader 副本都会下线, 因此, 需要为受影响的分区执行相应的 Leader 选举. 

这 4 类选举策略的大致思想是类似的, 即从 AR 中挑选首个在 ISR 中的副本, 作为新 Leader. 当然, 个别策略有些微小差异. 不过, 回答到这种程度, 应该足以应付面试官 了. 毕竟, 微小差别对选举 Leader 这件事的影响很小. 

## Kafka中有那些地方需要选举? 这些地方的选举策略又有哪些? 

参考：https://blog.csdn.net/u013256816/article/details/89369160

> 控制器的选举
>
> - Kafka Controller的选举是依赖Zookeeper来实现的, 在Kafka集群中哪个broker能够成功创建/controller这个临时（EPHEMERAL）节点他就可以成为Kafka Controller. 
>
> 分区leader的选举
>
> - https://www.jianshu.com/p/1f02328a4f2e
>
> 消费者相关的选举
>
> - 组协调器GroupCoordinator需要为消费组内的消费者选举出一个消费组的leader, 这个选举的算法也很简单, 分两种情况分析. 如果消费组内还没有leader, 那么第一个加入消费组的消费者即为消费组的leader. 如果某一时刻leader消费者由于某些原因退出了消费组, 那么会重新选举一个新的leader. 

## 15. Kafka 的哪些场景中使用了零拷贝(Zero Copy)?

Zero Copy 是特别容易被问到的高阶题目. 在 Kafka 中, 体现 Zero Copy 使用场景的地方有两处:**基于 mmap 的索引和日志文件读写所用的 TransportLayer**. 

先说第一个. 索引都是基于 MappedByteBuffer 的, 也就是让用户态和内核态共享内核态 的数据缓冲区, 此时, 数据不需要复制到用户态空间. 不过, mmap 虽然避免了不必要的 拷贝, 但不一定就能保证很高的性能. 在不同的操作系统下, mmap 的创建和销毁成本可 能是不一样的. 很高的创建和销毁开销会抵消 Zero Copy 带来的性能优势. 由于这种不确 定性, 在 Kafka 中, 只有索引应用了 mmap, 最核心的日志并未使用 mmap 机制. 

再说第二个. TransportLayer 是 Kafka 传输层的接口. 它的某个实现类使用了 FileChannel 的 transferTo 方法. 该方法底层使用 sendfile 实现了 Zero Copy. 对 Kafka 而言, 如果 I/O 通道使用普通的 PLAINTEXT, 那么, Kafka 就可以利用 Zero Copy 特 性, 直接将页缓存中的数据发送到网卡的 Buffer 中, 避免中间的多次拷贝. 相反, 如果 I/O 通道启用了 SSL, 那么, Kafka 便无法利用 Zero Copy 特性了. 

## 16. Kafka 为什么不支持读写分离?

这道题目考察的是你对 Leader/Follower 模型的思考. 

Leader/Follower 模型并没有规定 Follower 副本不可以对外提供读服务. 很多框架都是允 许这么做的, 只是 Kafka 最初为了避免不一致性的问题, 而采用了让 Leader 统一提供服 务的方式. 

不过, 在开始回答这道题时, 你可以率先亮出观点:
**自 ==Kafka 2.4 之后==, Kafka 提供了有限度的读写分离, 也就是说, Follower 副本能够对外提供读服务**. 

说完这些之后, 你可以再给出之前的版本不支持读写分离的理由. 

- **场景不适用**. 读写分离适用于那种读负载很大, 而写操作相对不频繁的场景, 可 Kafka 不属于这样的场景. 
- **同步机制**. Kafka 采用 PULL 方式实现 Follower 的同步, 因此, Follower 与 Leader 存 在不一致性窗口. 如果允许读 Follower 副本, 就势必要处理消息滞后(Lagging)的问题. 

## 17. ==如何调优 Kafka?==

回答任何调优问题的第一步, 就是**确定优化目标, 并且定量给出目标!**这点特别重要. 对于 Kafka 而言, 常见的优化目标是==**吞吐量, 延时, 持久性和可用性**==. 每一个方向的优化思路都 是不同的, 甚至是相反的. 

确定了目标之后, 还要明确优化的维度. 有些调优属于通用的优化思路, 比如对操作系统,  JVM 等的优化;有些则是有针对性的, 比如要优化 Kafka 的 TPS. 

**我们需要从 3 个方向去考虑**

- **Producer 端**:增加 ==batch.size==, ==linger.ms==, ==启用压缩==, ==关闭重试==等. 
- **Broker 端**:增加 ==num.replica.fetchers==, 提升 ==Follower 同步 TPS==, ==避免 Broker Full GC== 等. 
- **Consumer**:增加 ==fetch.min.bytes== 等

## 18. Controller 发生网络分区(Network Partitioning)时, Kafka 会怎 么样?

这道题目能够诱发我们对分布式系统设计, CAP 理论, 一致性等多方面的思考. 不过, 针 对故障定位和分析的这类问题, 我建议你首先言明"实用至上"的观点, 即不论怎么进行理论分析, 永远都要以实际结果为准. 一旦发生 Controller 网络分区, 那么, 第一要务就是 查看集群是否出现"脑裂", 即同时出现两个甚至是多个 Controller 组件. 这可以根据 Broker 端监控指标 ActiveControllerCount 来判断. 

现在, 我们分析下, 一旦出现这种情况, Kafka 会怎么样. 

由于 Controller 会给 Broker 发送 3 类请求, 即LeaderAndIsrRequest,  StopReplicaRequest 和 UpdateMetadataRequest, 因此, 一旦出现网络分区, 这些请求将不能顺利到达 Broker 端. 这将影响主题的创建, 修改, 删除操作的信息同步, 表现为 集群仿佛僵住了一样, 无法感知到后面的所有操作. 因此, 网络分区通常都是非常严重的问 题, 要赶快修复. 

## 19. Java Consumer 为什么采用单线程来获取消息?

在回答之前, 如果先把这句话说出来, 一定会加分:**Java Consumer 是双线程的设计. 一个线程是用户主线程, 负责获取消息;另一个线程是心跳线程, 负责向 Kafka 汇报消费者 存活情况. 将心跳单独放入专属的线程, 能够有效地规避因消息处理速度慢而被视为下线 的"假死"情况. **

单线程获取消息的设计能够避免阻塞式的消息获取方式. 单线程轮询方式容易实现异步非阻塞式, 这样便于将消费者扩展成支持实时流处理的操作算子. 因为很多实时流处理操作算子都不能是阻塞式的. 另外一个可能的好处是, 可以简化代码的开发. 多线程交互的代码是非常容易出错的. 

## 20. 简述 Follower 副本消息同步的完整流程

首先, Follower 发送 FETCH 请求给 Leader. 接着, Leader 会读取底层日志文件中的消 息数据, 再更新它内存中的 Follower 副本的 LEO 值, 更新为 FETCH 请求中的 fetchOffset 值. 最后, 尝试更新分区高水位值. Follower 接收到 FETCH 响应之后, 会把 消息写入到底层日志, 接着更新 LEO 和 HW 值. 

Leader 和 Follower 的 HW 值更新时机是不同的, Follower 的 HW 更新永远落后于 Leader 的 HW. 这种时间上的错配是造成各种不一致的原因. 

## 重点: kafka如何实现高吞吐? 

### 简单说说: kafka如何实现高吞吐? 

Kafka是分布式消息系统, 他的设计就是把消息写入大容量成本低的硬盘, 强大的存储能力, 并且在Kafka的优化下, ==**顺序写磁盘**效率比**随机写内存**还要高, 这是 Kafka 高吞吐率的一个很重要的保证== !

- **顺序读写**
- **零拷贝**
- **文件文段**
- **批量发送**
- **数据压缩**

具体来说:

读写文件依赖OS文件系统的页缓存, 而不是在JVM内部缓存数据, 利用OS来缓存, 内存利用率高
sendfile技术（零拷贝）, 避免了传统网络IO四步流程
支持End-to-End的压缩
顺序IO以及常量时间get, put消息.
多 Partition 可以很好的横向扩展和提供高并发处理.

### Kafka如何实现每秒上百万的超高并发写入? 

- **页缓存技术 + 磁盘顺序写**
  ![image-20220417153952975](https://s2.loli.net/2022/04/17/yMxkb4Kow79NYOD.png)

- **零拷贝技术**

  **kafka 使用了 sendFile 实现零拷贝.**
  **sendFile是特指将内核空间的数据, ==直接转到socket buffer==, 进行网络发送.**
  ![image-20220417170714805](https://s2.loli.net/2022/04/17/IzuyPoE1cnv4TmS.png)

# ==RocketMQ==

多个MQ如何选型? 

- **RabbitMQ**
  erlang开发，对消息堆积的支持并不好，当大量消息积压的时候，会导致 RabbitMQ 的性能急剧下降。每秒钟可以处理几万到十几万条消息。

- **RocketMQ**
  java开发，面向`互联网集群化`，功能丰富，对在线业务的响应时延做了很多的优化，大多数情况下可以做到毫秒级的响应，每秒钟大概能处理几十万条消息。

- **Kafka**
  Scala开发，面向`日志`，功能丰富，性能最高。当你的业务场景中，每秒钟消息数量没有那么多的时候，Kafka 的时延反而会比较高。所以，Kafka **==不太适合在线业务场景==**. => 所以出现了RocketMQ.

- **ActiveMQ**
  java开发，简单，稳定，性能不如前面三个。项目老旧, 社区不活跃, 对高并发的支持不成熟, 不推荐。

## 基础题

## RocketMQ组成部分(角色)有哪些? 

- **Nameserver**
  无状态，动态列表；这也是和zookeeper的重要区别之一。zookeeper是有状态的。
- **Producer**
  消息生产者，负责发消息到Broker。
- **Broker**
  就是MQ本身，负责收发消息、持久化消息等。
- **Consumer**
  消息消费者，负责从Broker上拉取消息进行消费，消费完进行ack。

## RocketMQ消费模式有几种?

- **集群消费**

  一条消息只会被同Group中的**==一个Consumer消费==**
  多个Group同时消费一个Topic时，每个Group都会有一个Consumer消费到数据

- **广播消费**

  消息将对一个Consumer Group 下的**==各个 Consumer 实例都消费一遍==**。即即使这些 Consumer 属于同一个Consumer Group ，消息也会被 Consumer Group 中的每个 Consumer 都消费一次。

## 消息重复消费如何解决? 

- **出现原因**
  正常情况下在consumer真正消费完消息后应该发送ack，通知broker该消息已正常消费，从queue中剔除
  当ack因为网络原因无法发送到broker，broker会认为词条消息没有被消费，此后会开启消息重投机制把消息再次投递到consumer。

  消费模式：在`CLUSTERING`模式下，消息在broker中会保证相同group的consumer消费一次，但是针对不同group的consumer会推送多次

- **解决方案**
  - 数据库表：处理消息前，使用消息主键在表中带有约束的字段中insert
  - Map：单机时可以使用map做限制，消费时查询当前消息id是不是已经存在
  - Redis：使用分布式锁。

## RocketMQ如何保证消息的顺序消费? 

只能一对一对一实现

可以使用同一topic，同一个queue，发消息的时候一个线程去发送消息，消费的时候 一个线程去消费一个queue里的消息。

## RocketMQ如何保证消息不丢失? 

- **Producer端**

  采取`send()`同步发消息，发送结果是同步感知的。
  发送失败后可以重试，设置重试次数。默认3次。

- **Broker端**
  修改刷盘策略为同步刷盘。默认情况下是异步刷盘的。
  集群部署

- **Consumer端**
  完全消费正常后在进行手动ack确认

## RocketMQ 由哪些角色组成? 

- 生产者（Producer）：负责产生消息，生产者向消息服务器发送由业务应用程序系统生成的消息。
- 消费者（Consumer）：负责消费消息，消费者从消息服务器拉取信息并将其输入用户应用程序。
- 消息服务器（Broker）：是消息存储中心，主要作用是接收来自 Producer 的消息并存储， Consumer 从这里取得消息。
- 名称服务器（NameServer）：用来保存 Broker 相关 Topic 等元信息并给 Producer ，提供 Consumer 查找 Broker 信息。

## RocketMQ执行流程

- 启动 Namesrv，Namesrv起 来后监听端口，等待 Broker、Producer、Consumer 连上来，相当于一个路由控制中心。
- Broker 启动，跟所有的 Namesrv 保持长连接，定时发送心跳包。
- 收发消息前，先创建 Topic 。创建 Topic 时，需要指定该 Topic 要存储在 哪些 Broker上。也可以在发送消息时自动创建Topic。
- Producer 发送消息。
- Consumer 消费消息。

## 请说说你对 Producer 的了解? 

- 获得 Topic-Broker 的映射关系。

  Producer 启动时，也需要指定 Namesrv 的地址，从 Namesrv 集群中选一台建立长连接。

  **生产者每 30 秒从 Namesrv 获取 Topic 跟 Broker 的映射关系**，更新到本地内存中。然后再跟 Topic 涉及的所有 Broker 建立长连接，每隔 30 秒发一次心跳。

- 生产者端的负载均衡。

  生产者发送时，会**自动轮询**当前所有可发送的broker，一条消息发送成功，下次换另外一个broker发送，以达到消息平均落到所有的broker上。

## 说说你对 Consumer 的了解? 

- 获得 Topic-Broker 的映射关系。

  Consumer 启动时需要指定 Namesrv 地址，与其中一个 Namesrv 建立长连接。消费者每隔 30 秒从 Namesrv 获取所有Topic 的最新队列情况，

  Consumer 跟 Broker 是长连接，会每隔 30 秒发心跳信息到Broker .

- 消费者端的负载均衡。

  根据消费者的消费模式不同，负载均衡方式也不同。

## 消费者消费模式有几种? 

- 集群消费

  消费者的一种消费模式。一个 Consumer Group 中的各个 Consumer 实例分摊去消费消息，即一条消息只会投递到一个 Consumer Group 下面的一个实例。

- 广播消费

  消费者的一种消费模式。消息将对一 个Consumer Group 下的各个 Consumer 实例都投递一遍。即即使这些 Consumer 属于同一个Consumer Group ，消息也会被 Consumer Group 中的每个 Consumer 都消费一次。

## 消费者获取消息有几种模式? 

- 推送模式 PushConsumer

  推送模式（虽然 RocketMQ 使用的是长轮询）的消费者。消息的能及时被消费。使用非常简单，内部已处理如线程池消费、流控、负载均衡、异常处理等等的各种场景。

- 拉取模式 PullConsumer

  拉取模式的消费者。应用主动控制拉取的时机，怎么拉取，怎么消费等。主动权更高。但要自己处理各种场景。

## 什么是定时消息? 如何实现? 

定时消息，是指消息发到 Broker 后，不能立刻被 Consumer 消费，要到特定的时间点或者等待特定的时间后才能被消费。

## 提高题

## RocketMQ如何实现分布式事务? 

1、生产者向MQ服务器发送half消息。
2、half消息发送成功后，MQ服务器返回确认消息给生产者。
3、生产者开始执行本地事务。
4、根据本地事务执行的结果（`UNKNOW`、`commit`、`rollback`）向MQ Server发送提交或回滚消息。
5、如果错过了（可能因为网络异常、生产者突然宕机等导致的异常情况）提交/回滚消息，则MQ服务器将向同一组中的每个生产者发送回查消息以获取事务状态。
6、回查生产者本地事物状态。
7、生产者根据本地事务状态发送提交/回滚消息。
8、MQ服务器将丢弃回滚的消息，但已提交（进行过二次确认的half消息）的消息将投递给消费者进行消费。

`Half Message`：预处理消息，当broker收到此类消息后，会存储到`RMQ_SYS_TRANS_HALF_TOPIC`的消息消费队列中

`检查事务状态`：Broker会开启一个定时任务，消费`RMQ_SYS_TRANS_HALF_TOPIC`队列中的消息，每次执行任务会向消息发送者确认事务执行状态（提交、回滚、未知），如果是未知，Broker会定时去回调在重新检查。

超时：如果超过回查次数，默认回滚消息。
也就是他并未真正进入Topic的queue，而是用了临时queue来放所谓的`half message`，等提交事务后才会真正的将half message转移到topic下的queue。

## RocketMQ的消息堆积如何处理? 

- 如果可以**添加消费者**解决，就添加消费者的数据量
- 如果出现了queue，但是消费者多的情况。可以使用**准备一个临时的topic**，同时**创建一些queue**，在临时创建一个消费者来把这些消息**转移到topic中**，让消费者消费。

